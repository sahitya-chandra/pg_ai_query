# PostgreSQL AI Query Extension Configuration
# Copy this file to ~/.pg_ai.config and modify as needed

[general]
# Logging configuration
log_level = "INFO"
enable_logging = true

# Request timeout in milliseconds (default: 30000 = 30 seconds)
request_timeout_ms = 30000

# Maximum number of retries for failed requests
max_retries = 3

[query]
# Automatically enforce LIMIT on SELECT queries for safety
enforce_limit = true

# Default row limit for queries (when no LIMIT is specified)
default_limit = 1000

[response]
# Show detailed explanation of what the query does
show_explanation = true

# Show warnings about performance, security, or data implications
show_warnings = true

# Show suggested visualization type for query results
show_suggested_visualization = true

# Use formatted response (JSON format) instead of plain SQL
# When enabled, returns structured JSON with query, explanation, warnings, etc.
# When disabled, returns plain SQL with optional comments
use_formatted_response = false

[openai]
# OpenAI API key - get from https://platform.openai.com
api_key = "your-openai-api-key-here"

# Default model to use (gpt-4o, gpt-4, gpt-3.5-turbo)
default_model = "gpt-4o"

# Custom API endpoint (optional) - for OpenAI-compatible APIs
# Note: Do NOT include /v1 - the SDK appends /v1/chat/completions automatically
# Examples:
#   - Ollama: http://localhost:11434
#   - LiteLLM: http://localhost:8000
#   - OpenRouter: https://openrouter.ai/api
#   - Together AI: https://api.together.xyz
#   - vLLM: http://localhost:8000
# api_endpoint = "https://api.openai.com"

[anthropic]
# Anthropic API key - get from https://console.anthropic.com
api_key = "your-anthropic-api-key-here"

# Default model to use
default_model = "claude-3-5-sonnet-20241022"

# Custom API endpoint (optional) - for Anthropic-compatible APIs
# api_endpoint = "https://api.anthropic.com"

[gemini]
# Google Gemini API key - get from https://ai.google.dev
api_key = "your-gemini-api-key-here"

# Default model to use (gemini-2.5-flash recommended for best price-performance)
default_model = "gemini-2.5-flash"
# Other available models:
# default_model = "gemini-2.5-pro"  # For complex reasoning tasks
# default_model = "gemini-2.5-flash-lite"  # For maximum speed/cost efficiency
# default_model = "gemini-3-pro-preview"  # For cutting-edge features (preview)

# Example Usage Scenarios:
#
# 1. INTERACTIVE DEVELOPMENT (recommended for learning and development)
#    show_explanation = true
#    show_warnings = true
#    show_suggested_visualization = false
#    use_formatted_response = false
#    Result: SQL with helpful comments and warnings
#
# 2. APPLICATION INTEGRATION (for programmatic use)
#    show_explanation = true
#    show_warnings = true
#    show_suggested_visualization = true
#    use_formatted_response = true
#    Result: Structured JSON with all metadata
#
# 3. PRODUCTION/MINIMAL (for performance-critical applications)
#    show_explanation = false
#    show_warnings = false
#    show_suggested_visualization = false
#    use_formatted_response = false
#    Result: Just the SQL query (fastest response)
#
# 4. BUSINESS INTELLIGENCE (for dashboards and reporting)
#    show_explanation = true
#    show_warnings = false
#    show_suggested_visualization = true
#    use_formatted_response = true
#    Result: JSON with explanations and visualization guidance